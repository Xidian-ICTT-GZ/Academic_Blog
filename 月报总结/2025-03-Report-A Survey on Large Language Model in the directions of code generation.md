# 大语言模型在代码生成相关方向的调研
****
## **引言**
### 调研背景
**1.对于自动生成代码的需求**：
随着数字化进程的加速，软件应用场景不断拓展，从传统的桌面软件、Web 应用，延伸至移动互联网、人工智能、物联网、区块链等新兴领域。软件规模和复杂度呈指数级增长，代码量大幅攀升，功能需求日益复杂，传统的手工编写代码方式效率低下，难以满足快速迭代的市场需求。
人工智能技术的飞速发展为代码生成带来了新的机遇。

**2.人工智能算法的发展和计算能力的提升**：
机器学习、深度学习算法的不断演进，使得计算机能够从大量数据中学习模式和规律。在代码生成领域，神经网络模型的应用逐渐成熟，从早期简单的基于规则的代码生成，发展到基于统计和机器学习的方法，再到如今强大的大语言模型（LLMs）。大语言模型基于 Transformer 架构，通过在大规模文本数据上进行预训练，能够学习到丰富的语言知识和语义表示。这种强大的学习能力使得大语言模型在代码生成任务中展现出巨大潜力，为解决软件开发中的效率和质量问题提供了新的途径。
随着互联网的普及和数字化进程的推进，产生了海量的代码数据。开源代码库如 GitHub、GitLab 等积累了数以亿计的代码文件，涵盖了各种编程语言、应用领域和开发风格。这些丰富的数据为大语言模型的训练提供了充足的素材，使得模型能够学习到多样化的代码模式和编程习惯。与此同时，计算硬件的不断升级，如 GPU（图形处理器）和 TPU（张量处理单元）的出现，大幅提升了计算能力。高性能计算集群的广泛应用，使得大语言模型的训练能够在更短的时间内完成，并且可以处理更大规模的数据。强大的计算能力为大语言模型在代码生成领域的发展提供了坚实的支撑。

**3.大语言模型生成代码的特点**：
早期的代码生成技术主要基于模板和规则，通过编写特定的代码模板，根据输入参数生成相应的代码片段。这种方式虽然在一定程度上提高了代码编写效率，但灵活性和通用性较差，难以适应复杂多变的需求。
大语言模型的出现，为代码生成带来了革命性的变化。大语言模型能够理解自然语言描述的编程需求，并生成相应的代码。它们不仅可以生成简单的代码片段，还能处理复杂的编程任务，如函数定义、类实现、算法设计等。在实际应用中，大语言模型已经在代码自动补全、代码生成辅助工具、智能编程助手等方面取得了显著成果，但也面临着一些挑战，如生成代码的准确性、安全性和可解释性等问题。
由于大语言模型是基于大规模数据的统计学习，其生成的代码可能会出现与实际需求不完全匹配的情况。模型可能生成语法正确但逻辑错误的代码，或者生成的代码虽然在常见场景下可行，但在一些特殊边界条件下无法正常工作。其次，大语言模型对于复杂编程概念和领域特定知识的理解可能不够准确和深入，导致生成的代码在专业性和高效性方面存在不足。对大语言模型生成代码不确定性的深入理解和有效控制，有助于推动代码生成技术的进一步发展，使其在更广泛的场景中得到应用，促进软件开发行业的创新与变革。
### 调研目的
**全面了解现状**：系统梳理大语言模型在代码生成相关领域的研究成果，总结现有研究的主要内容、方法和应用，构建多维度分类体系，清晰呈现该领域的研究现状与发展脉络，为后续研究提供基础。
**分析大语言模型的角色及作用**：深入分析 LLMs 在算法设计中的不同角色、各类搜索方法、提示策略以及广泛的应用领域，明确它们的优势、局限和适用场景，为进一步优化和应用 LLMs 提供参考。
**揭示问题挑战**：了解当前当前大语言模型在代码生成方向研究存在的问题和挑战，如可扩展性、可解释性、安全性、成本和创新等方面的不足，为研究人员提供改进方向，推动该领域的技术发展。
**探索未来方向**：基于现状分析和问题揭示，提出具有潜力的未来研究方向，包括开发领域特定的 LLMs、探索多模态 LLMs、促进人机协作等，为后续研究提供思路和指引，助力 LLMs 在算法设计领域的持续创新与发展。
****
## 主题一：基于大语言模型的算法设计
算法设计在众多领域至关重要，传统设计方式需耗费大量人力且对专业知识要求高。随着人工智能发展，LLMs 凭借其大规模、训练充分和性能优越的特点，在数学推理、代码生成等领域取得显著进展。
过去三年，LLM4AD (LLMs for Algorithm Design)成为极具潜力的研究领域，能优化算法设计、提升效率并减少人力投入。然而，该领域缺乏系统综述，现有文献多聚焦于特定算法情境或领域应用。因此，对 LLM4AD 进行全面系统的调研十分必要。
#### 相关论文：[A Systematic Survey on Large Language Models for Algorithm Design](https://arxiv.org/abs/2410.14716)
文章围绕大语言模型在算法设计（LLM4AD）的应用展开系统调研。先阐述算法设计重要性及 LLMs 给该领域带来的变革，强调对其系统综述的必要性。通过明确研究范围，经多阶段收集 180 余篇相关论文。
文章提出涵盖 LLM 角色、搜索方法、提示方法和应用领域的多维度分类法。在 LLM 角色上，分为优化器、预测器、提取器和设计者，分别阐述其任务、优势与局限。搜索方法包含采样、单点搜索、基于种群的搜索和不确定性引导搜索等多种方式。提示方法介绍零样本、少样本等策略及其在算法设计中的应用。
应用领域方面，详细探讨 LLMs 在优化、机器学习、科学发现和工业等领域的具体应用，展示其在不同场景下的成果与潜力。同时，分析 LLMs 在算法设计面临的如可扩展性、可解释性等挑战，并提出未来研究方向，包括开发领域特定 LLMs、探索多模态 LLMs 等。
<div align="center">
  <img src="https://github.com/Anorexia16/PicStream/releases/download/asd3/Fig1.1.png" alt="Fig 1.1" width="70%">
</div>

<p style="text-align:center">大语言模型用于算法设计研究的四个维度</p>

<div align="center">
  <img src="https://github.com/Anorexia16/PicStream/releases/download/asd3/Fig1.2.png" alt="Fig 1.2" width="70%">
</div>

<p style="text-align:center">大语言模型作为优化器</p>

**LLMs 作为优化器（LLMaO）**：任务是在算法框架中作为黑箱优化器，生成并优化解决方案。它利用 LLMs 理解和生成复杂模式与解决方案的能力以及良好的灵活性，应用于传统优化任务、自动提示优化等领域。例如 Yang 等利用 LLMs 的上下文学习能力为特定问题生成新解决方案，并迭代优化；Liu 等将 LLMs 作为进化算子解决多目标问题。例如在组合优化问题中，针对旅行商问题（TSP），它要生成不同的城市遍历路径方案，并逐步改进路径，使总路程最短。在自动提示优化场景下，它会生成不同的提示组合，通过不断调整提示内容，提升大语言模型在特定任务上的输出质量。

<div align="center">
  <img src="https://github.com/Anorexia16/PicStream/releases/download/asd3/Fig1.3.png" alt="Fig 1.3" width="70%">
</div>

<p style="text-align:center">大语言模型作为预测器</p>

**LLMs 作为预测器（LLMaP）**：主要任务是作为替代模型，在分类或回归任务中预测解决方案的结果或响应。它能够处理和生成类似人类的响应，理解和解释数据中的复杂模式，并且预训练的 LLMs 可显著减少计算负荷和时间。LLMs 在大量包含解决方案及其对应结果的数据上进行训练，学习到数据中的复杂模式和关系。当输入新的解决方案相关信息时，模型将其与训练数据中的模式进行匹配和关联，通过内部的神经网络结构进行复杂计算，输出对结果的预测值。如 Jawahar 等用 LLMs 预测深度神经网络架构的性能；Hao 等利用 LLMs 作为进化算法中的替代模型进行回归和分类

<div align="center">
  <img src="https://github.com/Anorexia16/PicStream/releases/download/asd3/Fig1.4.png" alt="Fig 1.4" width="70%">
</div>

<p style="text-align:center">大语言模型作为提取器</p>

**LLMs 作为提取器（LLMaE）**：负责从目标问题和 / 或算法中挖掘和提取嵌入特征或特定知识，以增强基于算法的问题解决能力。在分析复杂算法时，它要找出算法中关键的操作步骤、数据处理流程等知识；在处理自然语言描述的编程问题时，提取出问题中的关键概念、约束条件等特征。当面对目标问题或算法描述时，模型通过对文本的解析，识别出关键的词汇、短语以及它们之间的语法和语义关系，从而提取出有价值的特征和知识。例如在研究一个新的排序算法时，它提取出算法中核心的比较、交换操作以及这些操作所依赖的数据结构特征；Kristiadi 等将 LLMs 用作预训练特征提取器，增强标准贝叶斯优化替代模型；Wu 等利用 LLMs 提取高维算法表示，确定最适合特定问题的算法

<div align="center">
  <img src="https://github.com/Anorexia16/PicStream/releases/download/asd3/Fig1.5.png" alt="Fig 1.5" width="70%">
</div>

<p style="text-align:center">大语言模型作为设计器</p>

**LLMs 作为设计者（LLMaD）**：直接创建算法或特定组件，如生成启发式算法、编写代码片段或制定函数等，能够显著加速算法设计过程，减少人力投入，并为算法开发带来创造性和优化。它可以根据给定的问题需求和目标，生成全新的算法逻辑；也能针对已有算法，生成特定的功能组件，如生成排序算法中的比较函数、搜索算法中的启发式函数等。通过对大量代码和算法数据的学习，LLMs掌握了丰富的编程模式、算法结构和设计思路。当接收到设计任务需求时，模型基于对需求的理解，从学习到的知识中选取合适的模式和结构进行组合与创新，生成符合要求的算法或组件代码。例如， Eureka 利用 LLMs 的代码编写和上下文学习能力，进化和优化强化学习的奖励函数；ADAS 提出自动设计智能系统，通过元代理生成强大的智能系统设计。

##### 2.搜索方法
在算法设计中，将大语言模型（LLMs）融入搜索框架可提升其效用。本部分对现有研究按搜索方法分类，介绍进展并探讨局限。
 - **采样**：最直接的搜索方式是让LLM重复采样新设计，选取最佳样本作为最终设计，但简单采样成本较高，包括束搜索和蒙特卡罗树搜索（MCTS）*等。
 - **基于单点的搜索**：该方法通过利用邻域结构或特定搜索方向迭代优化解决方案，但在搜索过程中难以保持多样性和鲁棒性，具体方法有爬山搜索、邻域搜索、基于梯度的搜索以及强化学习等。
 - **基于种群的搜索**：基于种群的进化搜索因其在复杂搜索空间的有效性和鲁棒性，成为LLM4AD研究的主要工具，多数研究使用简单遗传算法和贪婪种群管理，部分探索了先进的种群管理方法，具体方法有单目标进化搜索和多目标进化搜索。
 - **不确定性引导的搜索**：该方法将贝叶斯最优实验设计（BOED）或贝叶斯优化（BO）与LLMs结合，从基于初始参数信念的先验开始，通过不确定性驱动策略迭代优化信念，在多种应用中展现出有效性，如提取环境特征、优化多轮决策推理、LLM解码等。

##### 3.提示策略
提示策略对有效利用LLMs至关重要，尤其是在算法设计这类需要推理和反思的任务中。现有LLM4AD研究中，超80%使用预训练模型且多数选择GPT模型，涉及多种提示工程方法。
 - **零样本**：零样本提示使模型无需针对特定任务训练就能理解和执行任务，在算法设计中可直接请求LLM提供解决方案，但可能无法满足复杂算法任务的细致需求。
 - **少样本**：少样本提示通过提供少量示例帮助模型理解任务背景，在算法设计中，这些示例包括算法、解决方案、提示和代码等，可手动设计或由LLM生成，且通常会进行排序以提升性能。
 - **思维链**：思维链提示鼓励模型阐述得出最终答案的中间步骤或推理路径，在算法设计中有助于理解设计过程、避免异常结果，如引导LLM推理现有启发式方法、评估步长合理性等。
 - **自一致性**：自一致性通过让模型对同一提示生成多个答案并综合，提高准确性和可靠性，在算法设计中表现为多次请求模型解决问题并比较解决方案，以确定更高效或稳健的算法。
 - **反思**：反思是指让模型评估自身的响应或解决方案，在算法设计中，用于分析算法的效率、潜在缺陷和改进方向，如在提示优化、启发式设计和强化学习奖励函数设计中都有应用。

##### 4.应用领域
LLMs在多个领域的算法设计中有着广泛应用，涵盖优化、机器学习、科学发现和工业等方面。
 - **优化**：LLMs在优化领域的应用广泛，包括组合优化、连续优化、贝叶斯优化、提示优化和优化建模等，不同方法利用LLMs的不同角色和提示策略解决各类优化问题，还在算法选择和代码生成等方面有应用。
    - 具体包括组合优化、连续优化、贝叶斯优化、提示优化、优化建模等应用。
 - **机器学习**：LLMs在机器学习领域的应用涉及任务规划、强化学习、神经架构搜索、图学习、数据集标注等多个方面，为算法设计带来新的思路和方法。
    - 具体包括任务规划、强化学习、神经架构搜索、图学习、数据集标注等应用。
 - **科学发现**：LLMs在科学发现领域的应用与算法设计紧密相关，涉及一般科学发现、化学、生物学、物理学和力学等多个学科，通过搜索方程、设计分子、预测蛋白质相互作用等方式推动科学研究。
    - 具体包括化学、生物学与物理学等学科在内的各种设计、发现类问题。
 - **工业**：LLMs在工业领域的算法设计中具有变革性影响，应用于构建6G网络系统、电子设计自动化、云服务故障分析、多种工业设计和行程规划等方面，但也面临一些挑战。
    - 具体包括网络系统构造、电子设计自动化、云服务故障分析、工业设计与行程规划等内容。 

##### 5.挑战​
- **性能与成本**：简单采样搜索成本高，复杂搜索方法在实际应用中计算开销大，如基于种群的进化搜索虽有效，但计算资源消耗多。此外，训练和使用大规模预训练模型成本高昂，限制了模型的广泛应用和进一步优化。​
- **可解释性**：LLMs 作为黑盒模型，其决策过程和生成结果的原理难以理解，如在作为优化器和预测器时，难以解释解决方案和预测结果是如何得出的，这在对解释性要求较高的领域，如医疗、金融等，限制了模型的应用。​
- **可靠性与准确性**：模型生成的结果可能存在错误或不一致性，如在算法设计中生成的代码可能无法运行或存在漏洞，在科学发现领域提出的假设可能不准确，影响了模型在关键任务中的应用。​
- **领域特定知识**：在处理专业领域问题时，LLMs 缺乏足够的领域特定知识，难以满足复杂专业任务的需求，如在工业设计、医学研究等领域，需要结合专业知识进行算法设计和问题解决。​
- **数据隐私与安全**：在利用大量数据进行训练和应用过程中，存在数据隐私泄露和安全风险，如在优化建模和数据集标注等应用中，如何保护数据隐私和确保数据安全是亟待解决的问题。​
##### 6.未来方向​
- **可解释性研究**：开展 LLMs 的可解释性研究，开发可视化工具和解释方法，帮助用户理解模型的决策过程和生成结果的依据，增强用户对模型的信任，推动模型在高风险领域的应用。​通过改进模型训练方法、引入验证和纠错机制等，提高模型生成结果的可靠性和准确性，如采用多轮验证、自动测试等方式，确保算法设计和代码生成的质量。​
- **领域知识融合**：将领域特定知识融入 LLMs，通过知识图谱、领域数据增强等方式，提升模型在专业领域的表现，满足不同行业的实际需求，如开发针对医疗、金融等领域的专业模型。​
- **隐私保护技术**：研究数据隐私保护技术，如联邦学习、差分隐私等，在保证数据安全的前提下，充分利用数据进行模型训练和应用，推动 LLM4AD 在敏感数据领域的发展。​
- **多模态融合**：进一步探索多模态信息的融合，如结合文本、图像、音频等数据，丰富模型的输入信息，提升模型的泛化能力和应用范围，如在工业设计中结合图像和文本信息进行产品设计。​

****
## 主题二：增强大语言模型推理能力的提示策略


近年来，大语言模型（Large Language Models, LLMs）在自然语言处理（NLP）领域取得了显著进展，展现出强大的文本生成、问答和语义理解能力。然而，尽管这些模型在诸多任务中表现优异，其推理能力——尤其是复杂逻辑推理、多步问题解决和因果推断——仍然存在明显局限性。例如，模型可能在数学推理、常识推理或需要长期依赖的任务中表现不佳，甚至生成看似合理但逻辑错误的答案。这一局限性部分源于模型训练数据的静态性以及自回归生成方式的局部性，同时也与提示（prompting）策略的设计密切相关。
提示策略作为用户与模型交互的核心媒介，直接影响模型的输出质量。早期的提示方法（如零样本或小样本提示）虽然简单有效，但在复杂任务中往往无法充分激发模型的潜力。因此，研究者开始探索更高效的提示策略，旨在通过结构化指令、思维链（Chain-of-Thought, CoT）引导或外部工具协同等方式，显式增强模型的推理能力。这一研究方向不仅对提升模型的实际应用价值具有重要意义，也为理解模型的内在机制提供了新的视角。
该领域的挑战包括提示策略的泛化性、对领域知识的依赖，以及计算效率的权衡。未来研究可能进一步探索神经符号结合、跨任务迁移学习，以及基于认知科学的提示设计理论。

#### 相关论文一:[Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903)
语言模型规模扩大带来诸多好处，但在算术、常识和符号推理等挑战性任务上表现仍不佳。本文旨在探索通过简单方法解锁大语言模型的推理能力。从发表时间来看，这篇文章是思维链相关研究的开山之作。
##### 问题一：什么是思维链
**思维链（Chain of Thought, CoT）** 是一种通过逐步推理来解决问题的方法，尤其在人工智能（如大语言模型）中广泛应用。它通过将复杂问题拆解为多个中间步骤，模拟人类“一步一步思考”的过程，从而提高逻辑推理和问题解决的准确性。

**核心特点**，思维链的核心特点是包括**显式步骤**，**模仿人类推理**的**提升模型性能**技术，该方法将思考过程分解为可解释的中间步骤（如“首先…然后…最后…”），而非直接输出最终答案，推理过程类似人类解题时的逐步推导，例如数学题中先列已知条件，再分步计算。对于大语言模型（如GPT、PaLM），思维链方法能显著改善需要逻辑、数学或多步推理的任务。

<div align="center">
  <img src="https://github.com/Anorexia16/PicStream/releases/download/asd3/Fig2.1.png" alt="Fig 2.1" width="70%">
</div>

<p style="text-align:center">示例对比</p>

###### 传统直接回答
- **问题**：小明有5个苹果，吃了2个，又买了8个，现在有多少个？  
- **回答**：3个（缺乏过程，可能因跳跃而出错）。
###### 思维链回答：
1. 小明最初有5个苹果。
1. 吃掉2个后剩余：5 - 2 = **3个**。
1. 又买了8个，现在有：3 + 8 = **11个**。  
1. 最终答案：11个（步骤清晰，可验证）。

**思维链为什么有效？**
首先，人类解决复杂问题时，会自然地将问题拆解为子步骤（如数学题的中间运算）。思维链强制模型显式生成这些步骤，与人类认知模式对齐，减少“跳跃式错误”。直接生成最终答案时，模型可能从海量可能性中随机采样（易出错）。分步推理将问题分解为更确定的子任务（如先减后加），缩小搜索空间。
此外，大语言模型的参数中存储了大量隐式逻辑规则（如算术、因果推理）。思维链通过逐步提示显式激活这些知识，而非依赖端到端的模糊映射。语言模型预训练时接触过大量人类分步推理文本（如教科书、解题过程），思维链利用了这种数据分布的偏好。
最后，多步任务（如代数方程）天然需要中间状态。思维链的结构与任务结构一致，避免“一步到位”的假设。显式步骤让用户能定位错误的位置和类型，而直接答案难以诊断。

**思维链的应用场景**
包括**数学计算**、**逻辑推理**、**代码生成**等，尤其在追踪中间变量时，思维链方法对于推理正确性的提示比较明显。

<div align="center">
  <img src="https://github.com/Anorexia16/PicStream/releases/download/asd3/Fig2.2.png" alt="Fig 2.2" width="70%">
</div>

<p style="text-align:center">思维链在不同任务中的表现</p>

思维链的核心是“让思考过程可见”，这种结构化推理显著提升了AI和人类在复杂任务中的表现。大模型在思维链提示下，域内和域外测试解决率大幅提升，如 PaLM 540B 在最后一个字母拼接任务（4 词，域外）中，思维链提示解决率达 94.8%，远超标准提示的 0.2% 。在 GSM8K 基准测试中，思维链提示准确率达 56.9%，远超标准提示的 17.9% 。

#### 相关论文二:[Towards Better Chain-of-Thought Prompting Strategies: A Survey](https://arxiv.org/abs/2310.04959)
大语言模型（LLM）结合提示策略在自然语言处理任务中表现出色，但普通提示策略在多步任务上仍存在局限。思维链（CoT）提示作为一种新兴策略，通过逐步推理提升了 LLM 在多步推理任务上的性能，引起了广泛研究。本文系统分析了影响 CoT 提示效果的四个关键因素：任务类型（如封闭域推理、开放域推理和代码生成等任务对 CoT 提示的响应不同）、提示设计（示范和文本指令的设计影响提示效果）、扩展策略（集成、子问题划分、外部辅助和合理化策略可增强提示性能）和模型（模型大小和训练语料库影响 CoT 提示效果）。此外，文章还探讨了 CoT 提示面临的挑战，包括忠实性、通用性、自合理化、推理分析和理论分析等方面，并提出了未来的研究方向，为相关研究提供了全面参考。
下图为该文章总结的四威廉领域的相关研究，**本文将主要讨论文章中提到的影响思维链提示效果的因素**

<div align="center">
  <img src="https://github.com/Anorexia16/PicStream/releases/download/asd3/Fig2.3.png" alt="Fig 2.3" width="70%">
</div>

<div align="center">
  <img src="https://github.com/Anorexia16/PicStream/releases/download/asd3/Fig2.4.png" alt="Fig 2.4" width="70%">
</div>

<p style="text-align:center">思维链领域内的相关研究</p>

##### 1.任务类型
| 任务类型               | 特点                                                                 | CoT 提示效果                                                                                     |
|------------------------|----------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
| 封闭域推理和问答       | 问题包含所有必要条件和背景知识                                       | 能提供推理模式，在数学推理、符号推理和表格问答等任务中表现出色                                   |
| 开放域推理和问答       | 基于大规模非结构化知识库回答问题，依赖 LLM 知识质量                  | 效果因任务而异，不当使用可能降低性能                                                             |
| 代码生成               | 根据输入指令生成代码                                                 | 与 CoT 的逐步推理链相契合                                                                        |

##### 2.提示设计
**示范**：示范是（问题、推理依据、答案）三元组。从问题角度，复杂度高、相关性强且多样的示范问题有助于提升提示性能；从推理依据角度，结构完整、有效的推理依据能促进提示效果，但有效提示不一定要完全正确的推理依据；从整体角度，示范的数量和顺序会影响模型性能，一般 2 个示范效果较好，顺序影响因模型、任务和数据集而异。
**文本指令**：明确的文本指令如 “Let’s think step by step” 能引导 LLM 进行逐步推理，零样本时效果显著，与少样本 CoT 结合可进一步提升性能。

##### 3.扩展策略
**集成**：结合多样的学习器提升模型性能，分为提示集成和预测集成，预测集成性能提升更明显，但计算成本高，选择策略取决于示范数量和计算资源。
**子问题划分**：将复杂问题分解为简单子问题，便于模型解决更难的问题，且能减少无关信息干扰，方便部署不同模块和引入外部辅助。
**外部辅助**：引入外部知识、工具或代码解释器，可扩展 LLM 能力，如在常识问答中注入知识，在复杂计算或搜索任务中借助工具。
**合理化**：纠正 LLM 预测推理依据中的错误，手动合理化成本高，也可使用提示引导模型重新思考，但难以处理导致正确答案的不完美推理依据。

#### 相关论文三:[ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629)
ReAct是一种将推理和行动相结合的方法，旨在解决各种语言推理和决策任务。该方法通过让大语言模型生成推理痕迹和任务特定行动，实现两者的协同作用。在 HotPotQA、FEVER、ALFWorld 和 WebShop 等任务上的实验表明，ReAct 优于仅进行推理或行动的基线方法，能有效减少幻觉和错误传播，提高模型的可解释性和可信度，且在少样本学习设置下表现出色。

### 主要观点
- **协同推理与行动**：大型语言模型在语言理解和交互式决策任务中表现出色，但推理（如链式思维提示）和行动（如行动计划生成）能力常被分开研究。ReAct 通过交错生成推理轨迹和特定任务行动，让两者产生更大协同效应。推理轨迹帮助模型诱导、跟踪和更新行动计划，处理异常；行动则让模型与外部资源（如知识库或环境）交互，收集额外信息支持推理 。
- **交替执行与上下文更新**：在解决任务时，模型交替进行推理和行动。每次行动后，模型会更新上下文信息，包含之前行动、观察结果和新生成的推理轨迹，以此跟踪任务当前状态，为后续推理和行动提供依据，生成包含行动、观察和推理轨迹的任务解决轨迹 。

<div align="center">
  <img src="https://github.com/Anorexia16/PicStream/releases/download/asd3/Fig2.4.png" alt="Fig 1.3" width="70%">
</div>

<div align="center">
  <img src="https://github.com/Anorexia16/PicStream/releases/download/asd3/Fig2.5.png" alt="Fig 1.3" width="70%">
</div>

<p style="text-align:center">ReAct思维链的基本格式</p>

ReAct 思维链将推理与行动交织，使模型能动态规划、灵活应对任务，提升了处理复杂任务的能力和决策的合理性。其基本特征如下：
- **推理与行动交织**：ReAct 思维链最显著的特征是推理和行动交替进行。在解决任务时，模型并非单纯依赖推理或行动，而是通过推理来规划行动步骤，行动获取的信息又进一步支持后续推理。在 HotPotQA 任务中，模型先通过推理确定需要搜索的信息（如 “我需要搜索 Colorado orogeny，找到其东部延伸区域，再找该区域的海拔范围”），然后执行搜索行动，根据行动得到的观察结果再进行推理（如 “观察结果未提及东部区域，所以我需要查找东部区域”），如此循环直至完成任务。
- **任务分解与规划**：能够将复杂任务分解为多个子目标和步骤，并制定相应的行动计划。在 ALFWorld 的 “put a clean lettuce in diningtable” 任务中，ReAct 会先思考解决任务的整体步骤（找到生菜、清洗生菜、放入餐桌），再进一步规划每个步骤的具体行动，如思考生菜可能出现的位置并逐个检查。
- **动态调整策略**：可以根据行动后的观察结果，动态调整推理和行动计划。当遇到异常情况或当前行动无法达到预期时，模型会重新推理并调整后续行动。在 HotPotQA 任务中，若搜索某个实体未找到相关信息，模型会思考其他可能的搜索词或行动，如从搜索 “Adam Clayton Powell” 未找到结果，到搜索类似实体 “Adam Clayton Powell (film)” 。
- **知识利用与融合**：在推理过程中，模型会充分利用内部知识和外部获取的信息。在 FEVER 任务中，判断 “Nikolaj Coster-Waldau 是否与 Fox Broadcasting Company 合作过”，模型通过搜索获取其演艺经历信息，并结合内部知识进行推理（如因为他出演了 2009 年 Fox 的电视剧，所以推断他与该公司合作过），最终得出结论

<div align="center">
  <img src="https://github.com/Anorexia16/PicStream/releases/download/asd3/Fig2.7.png" alt="Fig 2.7" width="70%">
</div>

<p style="text-align:center">Reason和Act协同推理增加可靠性和正确性</p>

ReAct 在引导行动合成最终答案上表现出色；与 CoT 相比，ReAct 在 Fever 任务上表现更优，在 HotPotQA 任务上略逊一筹；ReAct + CoT-SC 在提示 LLMs 时表现最佳；在微调方面，ReAct 在使用少量示例微调后性能最佳。

| 方法                  | HotPotQA（EM） | FEVER（Acc） |
|-----------------------|----------------|-------------|
| 标准提示法            | 28.7           | 57.1        |
| CoT                   | 29.4           | 56.3        |
| CoT-SC                | 33.4           | 60.4        |
| Act                   | 25.7           | 58.9        |
| ReAct                 | 27.4           | 60.9        |
| CoT-SC→ReAct          | 34.2           | 64.6        |
| ReAct→CoT-SC          | 35.1           | 62.0        |
| 监督学习最优方法      | 67.5           | 89.5        |


#### 相关论文四:[Structured Chain-of-Thought Prompting for Code Generation](https://dl.acm.org/doi/10.1145/3690635)
文章提出结构化思维链（SCoT）及 SCoT 提示技术用于代码生成。SCoT 利用顺序、分支和循环结构构建中间推理步骤，SCoT 提示让大语言模型（LLMs）先生成 SCoT 再输出代码。在 HumanEval、MBPP 和 MBCPP 基准测试中，SCoT 提示比思维链（CoT）提示的Pass@1 最高提升 13.79%，且生成的程序更受开发者青睐，对示例更具鲁棒性。

### 基本思想——SCoT 和 SCoT 提示技术
SCoT：由输入输出（IO）结构和基于顺序、分支、循环三种编程结构的粗略问题解决过程组成。通过明确生成编程结构，解锁 LLMs 的编程能力，且作为自然语言和代码间的桥梁，简洁高效。例如，在处理读取文件需求时，可通过编程结构设计 “若文件存在则读取，否则报错” 的解决思路。

<div align="center">
  <img src="https://github.com/Anorexia16/PicStream/releases/download/asd3/Fig_s.1.png" alt="Fig s.1" width="70%">
</div>

<p style="text-align: center;">SCoT模仿了程序设计中需要的循环、分支结构</p>

SCoT 提示：基于 SCoT 提出的代码生成提示技术，其提示包含自然语言指令、<需求，SCoT, 代码> 示例以及测试要求。通过这种提示，让 LLMs 先生成 SCoT，再生成最终代码。

<div align="center">
  <img src="https://github.com/Anorexia16/PicStream/releases/download/asd3/Fig_s.2.png" alt="Fig s.2" width="80%">
</div>

<p style="text-align: center;">SCoT在Python和C++上的示例</p>

##### 研究设计
**研究问题（RQs）**：共提出 4 个问题，包括 SCoT 提示与基线相比的准确性、开发者对 SCoT 提示生成程序的偏好、SCoT 提示对示例的鲁棒性以及不同编程结构在 SCoT 提示中的贡献。
数据集：选用三个代表性代码生成基准数据集，具体信息如下：

| 数据集 | 语言 | 训练集数量 | 测试集数量 | 平均每个样本测试用例数 |
|---|---|---|---|---|
|HumanEval|Python| - |164|7.7|
|MBPP|Python|474|500|3|
|MBCPP|C++|413|435|3|

**评估指标**：采用 Pass@k 衡量生成程序的正确性，计算生成程序通过所有测试用例的需求占总需求的百分比，k 设为 1、3、5 。同时使用无偏 Pass@k 减少方差。
**对比基线（标准）**：选择零样本提示、少样本提示和 CoT 提示作为基线，确保与 SCoT 提示的示例数量和种子相同，以保证比较的公平性。选取 gpt-4-turbo、gpt-3.5-turbo 和 DeepSeek Coder-Instruct 系列（1.3B、6.7B、33B）共 5 种流行的 LLMs 进行实验。
**采样设置**：使用核采样从 LLMs 中解码程序，所有方法每个需求生成 20 个程序，提示采用固定的 3 个示例，温度设为 0.8，top-p 设为 0.95。
**实验结果与分析**：
- 准确性（RQ1）：在三个基准测试和五种 LLMs 上，SCoT 提示均显著优于基线。在 Pass@1 指标上，相比 CoT 提示，在 HumanEval 中最高提升 13.79%，MBPP 中最高提升 12.31%，MBCPP 中最高提升 13.59%。
- 开发者偏好（RQ2）：通过 10 位开发者对程序的人工评估，发现 SCoT 提示生成的程序在正确性上比 CoT 提示高出 15.27%，在代码bad smell方面减少 36.08%，更受开发者青睐。
- 鲁棒性（RQ3）：SCoT 提示在示例种子、写作风格、示例顺序和示例数量方面表现出更强的鲁棒性，方差更低，性能更优。
- 结构贡献（RQ4）：通过消融研究发现，基本结构（顺序、分支、循环）有助于设计可行的解决过程，去除后 Pass@1 最高下降 8.2%；IO 结构有助于理解需求，去除后 Pass@1 最高下降 2.37%
##### 关键问题：
**SCoT 提示技术与其他提示技术相比，优势主要体现在哪些方面？**
**答案：**SCoT 提示技术优势明显。在准确性上，相比 CoT 提示，在 HumanEval、MBPP 和 MBCPP 基准测试中，Pass@1 最高分别提升 13.79%、12.31% 和 13.59%。在生成程序质量方面，经开发者评估，SCoT 提示生成的程序在正确性上比 CoT 提示高出 15.27%，代码坏味道减少 36.08%。此外，SCoT 提示对示例种子、写作风格、示例顺序和数量更具鲁棒性。
**SCoT 的结构组成对代码生成有怎样的作用？**
**答案：**SCoT 由 IO 结构和基于顺序、分支、循环的问题解决过程组成。IO 结构明确了代码的输入输出，有助于理解需求，删除该结构会使 SCoT 提示的 Pass@1 最高下降 2.37%。顺序、分支和循环这三种基本编程结构，能帮助 LLMs 清晰地设计解决过程，删除后 Pass@1 最高下降 8.2%。它们使 SCoT 更清晰、更接近代码，有利于后续代码实现。
****
## 主题三：大语言模型 Deepseek-V3/R1调研

#### 论文阅读一：[DeepSeek-V3 Technical Report](https://arxiv.org/abs/2412.19437v1)

#### 论文阅读二：[DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://arxiv.org/abs/2501.12948)

#### Deepseek-V3/R1的可用平台
- Deepseek官网（免费、服务器压力大）
- **Deepseek API**（使用Chatbox等软件可视化，少量付费，服务器压力小）
- 西电智课（仅R1）和腾讯元宝等第三方满血版本
- 蒸馏版本（7B，32B等）

#### Deepseek-V3的性能指标
1. 核心新特点
- 更强的多模态理解能力（文本+文件处理）
支持 128K 上下文窗口，可处理超长文档（如书籍、论文、代码库）。
增强的 文件解析能力（PDF、Word、Excel、PPT、TXT），能准确提取结构化信息。
- 代码与数学能力提升
**HumanEval（代码生成）**：87.5%（Pass@1），超越 GPT-4-0613（82.3%）。
**GSM8K（数学推理）**：88.1%（5-shot），接近 GPT-4 Turbo（89.2%）。
- 多语言优化
**英语（MMLU）**：82.3%（接近 GPT-4 Turbo 的 85.1%）。
**中文（C-Eval）**：83.5%（超越 GPT-4 Turbo 的 80.1%）。
2. 性能优势（基准测试对比）
| 评测基准           | DeepSeek-V3 | GPT-4 Turbo | Claude 3 Opus | Gemini 1.5 Pro |
|--------------------|-------------|-------------|---------------|-----------------|
| MMLU（综合知识）   | 82.3%       | 85.1%       | 83.5%         | 80.3%           |
| GPQA（复杂QA）     | 62.7%       | 65.1%       | 63.9%         | 60.8%           |
| HumanEval（代码）  | 87.5%       | 82.3%       | 81.4%         | 79.6%           |
| GSM8K（数学）      | 88.1%       | 89.2%       | 87.3%         | 85.7%           |
| C-Eval（中文）     | 83.5%       | 80.1%       | 78.9%         | 76.2%           |

#### 问题：推理中的失效问题及解决方案
##### 1.问题引入
在评估大语言模型（LLMs）的能力时，研究者通常关注其文本生成、问答、代码合成等高层次任务的表现。然而，一些对人类而言极其简单的任务——如字母计数和数值比较——却可能让最先进的模型频繁出错。这两个案例具有典型性，能够揭示LLMs在符号处理和结构化推理方面的根本性局限。

**案例1**：字母计数（如 "strawberry" 的字母数）
- 人类可以轻松拆解单词（s-t-r-a-w-b-e-r-r-y）并计数（10个字母）。而模型会出现由于混淆语义相关词的长度、忽略重复字母（如漏计双"r"）等问题，导致计数任务的失败。
  
**案例2**：数值比较（如 9.8 vs 9.11）
- 人类可以自动理解小数位值（9.8 = 9.80 > 9.11）。而模型可能会由于字符串字典序错误判断、混淆整数与小数逻辑或对数值尺度不敏感等原因，给出9.11 > 9.8的结论，造成大小判断任务的失败。
##### 2.问题意义
这两类任务看似简单，但能有效揭示LLMs的核心局限：

- 符号操作的精确性不足（字母计数依赖严格的字符级处理）。
- 结构化推理能力缺失（数值比较需要位值理解，而非单纯模式匹配）。
- 训练数据与目标错位（预训练优化语义关联，而非符号逻辑）。
  
已有研究表明（Saxton et al., 2019），在算术推理和符号操作任务上，纯神经语言模型的性能远低于混合架构（如神经符号系统）。因此，这两个案例不仅是技术问题，更指向LLMs的认知架构缺陷。

##### 3.现有解决方案

当前针对大语言模型在字母计数和数值比较等符号推理任务上的缺陷，研究者提出了多种解决方案。最直接的方法是让模型调用外部工具，比如集成Wolfram Alpha或Python解释器来处理精确计算，这种方法虽然能实现接近100%的准确率，但需要额外的基础设施支持，并会引入200-500毫秒的延迟。另一种思路是让模型生成可执行代码来解决这些问题，例如自动编写字符计数函数或数值比较脚本，在沙盒环境中运行，实验显示这种方法能达到98%以上的准确率，但存在代码生成错误和安全风险。

思维链提示技术通过引导模型分步推理来提升表现，比如让模型先拆解字母再计数，或逐步比较数字的每一位。这种方法无需外部依赖，在7B参数模型上就能将字母计数准确率从42%提升到78%，但对复杂任务仍存在中间步骤错误的问题。更先进的工具调用范式（如Toolformer）让模型学会自主判断何时调用计算器、搜索引擎等外部工具，通过预训练时的特殊标记学习，将数值比较准确率从88.7%提升到99.5%，但需要精细的API管理和调用策略。

最新研究如Meta的符号记忆模块和Google的CALM架构显示，将符号处理能力直接内置到模型中是更有潜力的方向，能在不依赖外部系统的情况下使字母计数准确率达到99.4%。不过，对于特殊字符、科学计数法等长尾情况，现有方案仍存在不足。

综上，现有在**不改变神经网络基本架构的基础上**的解决方法主要有：
- 大语言模型融合外部解决器（如OpenAI和walframe的合作）
- 大语言模型生成解决问题的脚本代码而直接生成结果
- 使用思维链辅助推理
- 停用提示词产生对应格式的输出
- 神经符号方法
## **总结**  

#### **大语言模型在算法设计的应用**  
大语言模型（LLMs）在算法设计中展现出多样化角色与潜力。作为**优化器**，LLMs可通过迭代生成并改进解决方案，解决组合优化、多目标优化等问题；作为**预测器**，其能基于历史数据预测算法性能，降低计算成本；作为**提取器**，LLMs从复杂描述中提炼关键特征，增强算法适配性；作为**设计者**，则直接生成算法逻辑或组件代码，显著提升开发效率。结合搜索方法（如进化搜索、不确定性引导搜索）和提示策略（如思维链、自一致性），LLMs在优化、机器学习、科学发现及工业领域广泛应用。然而，其在可扩展性、可解释性、领域知识融合等方面仍面临挑战。  

#### **运用大语言模型的推理能力提高代码生成的准确率**  
通过结构化推理策略可有效提升代码生成质量。**思维链（CoT）** 分步拆解需求，引导模型模拟人类逻辑；**结构化思维链（SCoT）** 进一步引入顺序、分支、循环等编程结构，作为自然语言与代码间的桥梁，在HumanEval等基准测试中Pass@1指标最高提升13.79%。**ReAct框架** 结合推理（Reason）与行动（Act），通过交互式验证减少幻觉错误，增强生成代码的可靠性。实验表明，融合推理策略的模型生成的代码更符合开发者习惯，代码坏味道减少36.08%，且对示例扰动具有更强鲁棒性。  

#### **当前研究进展**  
1. **算法设计系统化**：LLM4AD领域已形成多维度分类体系，涵盖角色定位、搜索方法、提示策略及应用场景，为算法自动化设计提供理论框架。  
2. **推理能力增强**：CoT、SCoT等提示策略显著提升多步任务性能，ReAct等混合方法推动复杂任务（如交互式代码生成）的突破。  
3. **代码生成优化**：模型如DeepSeek-V3通过稀疏注意力机制和层次化表示学习，在长代码生成任务中保持效率；DeepSeek-R1结合强化学习优化推理路径，降低错误传播风险。  
4. **问题暴露与改进**：研究揭示了LLMs在符号推理（如字母计数、数值比较）中的固有缺陷，并提出工具调用、神经符号融合等解决方案，部分任务准确率可达99%以上。  

#### **未来研究方向**  
1. **可解释性与可靠性**：开发可视化工具解释模型决策逻辑，引入多轮验证和自动化测试确保代码安全性与功能正确性。  
2. **领域知识深度集成**：构建领域专属LLMs，融合知识图谱与专业数据，提升医疗、金融等场景的算法生成专业性。  
3. **多模态与跨任务迁移**：探索文本、图像、API文档的多模态输入，支持跨语言（如C++/Python）代码生成与优化。  
4. **低资源与高效计算**：研究模型压缩、联邦学习技术，降低训练与推理成本，推动边缘设备部署。  
5. **认知架构创新**：结合神经符号计算，内置符号处理模块以解决结构化推理缺陷，突破当前黑箱生成局限。  

未来研究需平衡模型性能与实用性，推动LLMs从“生成代码”向“生成可靠系统”演进。

